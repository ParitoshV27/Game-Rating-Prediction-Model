# ğŸ® Game Rating Prediction Using Pre- and Post-Release Features

A two-stage **machine learning framework** to predict **video game critic and user ratings** by modeling the game lifecycle â€” **before release (expectations)** and **after release (player experience)**.

This project is designed as a **research-oriented study** and is accompanied by a conference-style paper.

---

## ğŸš€ Project Overview

Video game reception changes over time:

- **Before release** â†’ ratings are driven by expectations, studio reputation, pricing, and perceived scope  
- **After release** â†’ ratings are driven by gameplay quality, replayability, and execution

To capture this distinction, this project implements **two separate models**:

### ğŸŸ¦ Model 1: Pre-Release Prediction  
Predicts expected ratings using only features available **before launch**.

### ğŸŸ© Model 2: Post-Release Prediction  
Predicts realized ratings using **execution-level in-game features**.

Critic ratings and user ratings are modeled **independently** in both stages.

---

## ğŸ“Š Dataset

The dataset was **manually curated** and engineered from publicly available sources.

### ğŸ”— Data Sources
- IGDB  
- HowLongToBeat  
- IGN  
- Steam  
- Metacritic  
- IMDb  

### ğŸ—‚ Dataset Versions
- **Pre-release dataset:** 170 games (final version used for Model 1 results)
- **Post-release dataset:** Expanded dataset used for Model 2

The dataset emphasizes **interpretability, temporal validity, and feature relevance** rather than scale alone.

---

## ğŸ›  Feature Engineering

### ğŸ”¹ Pre-Release Features
- Genre, platforms, modes (counts + binary indicators)
- Launch price and playtime-based value metrics
- Open-world, sequel/spinoff, modding support
- Studio and franchise historical average ratings
- Unique factor indicator for non-generic experiences

### ğŸ”¹ Post-Release Features
- Story depth
- Gameplay quality
- Replayability
- World immersion
- Narrative and audio quality indicators

Derived features such as **price per story hour** and **content density** were used to capture perceived value.

---

## ğŸ¤– Models Used

- ğŸŒ³ Random Forest Regressor (primary model)
- ğŸ“ˆ Gradient Boosting Regressor
- âš¡ XGBoost Regressor

Random Forest was selected as the primary model due to its **robust performance and interpretability**.

---

## ğŸ“ Evaluation Metrics

Models were evaluated using:
- Mean Absolute Error (MAE)
- Root Mean Squared Error (RMSE)
- RÂ² Score

All evaluations were performed **separately for critics and users**.

---

## ğŸ§  Key Findings

- Pre-release prediction shows **moderate predictability**, driven mainly by:
  - Studio reputation
  - Pricing
  - Modding support
- Post-release prediction achieves **significantly higher accuracy**, dominated by:
  - Replayability
  - Gameplay quality
  - Narrative depth
- Critic ratings are more predictable than user ratings
- Replayability is the strongest post-release predictor across models

---

## ğŸ“ Repository Structure

game-rating-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Games List 170.csv
â”‚   â”œâ”€â”€ In Game Features.csv
â”‚   â””â”€â”€ games_engineered.md
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ game_rating_prediction_pre_release.ipynb
â”‚   â”œâ”€â”€ game_rating_prediction_post_release.ipynb
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ metrics_summary.txt
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt



---

## ğŸ“„ Research Paper

A **conference-style research paper** based on this project is currently **in preparation**, covering:
- Dataset construction
- Feature engineering
- Model comparison
- Results, discussion, and future work

---

## âš  Notes

- This repository is intended as a **research artifact**
- Focus is on **interpretability and lifecycle-aware modeling**
- Large language models were used only for **limited assistance in feature standardization**, with all outputs manually reviewed

---

## ğŸ‘¤ Author

**Paritosh Vishwasrao**

ğŸ“ Aspiring MS in Data Science / AI  
ğŸ“Š Interests: Applied ML, Game Analytics, Predictive Modeling

---


